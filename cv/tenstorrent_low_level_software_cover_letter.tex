\documentclass[11pt]{article}
\usepackage[margin=1in]{geometry}
\usepackage[hidelinks]{hyperref}
\usepackage{setspace}
\setstretch{1.05}
\pagenumbering{gobble}
\usepackage{parskip}
\setlength{\parindent}{0pt}
\usepackage[T1]{fontenc}
\usepackage{lmodern}

\begin{document}

{\Large \textbf{Yongkang Cheng}}\\[2pt]
\href{https://chengyongkang.me/}{chengyongkang.me} \;|\; 437-663-2855 \;|\; \href{mailto:iwmain@outlook.com}{iwmain@outlook.com} \;|\; \href{https://github.com/Ken-2511}{github.com/Ken-2511}

\today\\[0.8em]

Dear Hiring Manager,

I am a Computer Engineering PEY student at the University of Toronto (cGPA 3.87/4.0) and I am applying for the Tenstorrent Low-Level Software Internship in Toronto. Your mission to turn custom RISC-V compute into production-ready AI performance aligns squarely with how I like to work: close to the metal, profiling and tuning until workloads run measurably faster. I am based in Toronto and fully available for an on-site term.

The most relevant proof of fit is my C++ City Mapify engine. I owned the pathfinding and rendering kernels on 2 GB OpenStreetMap data, designing cache-aware adjacency layouts and templated heuristics to sustain 60 FPS while routing 250+ deliveries. I built microbenchmarks, perf annotations, and flame graphs to chase memory stalls and branch mispredicts—habits that translate directly to investigating kernel performance on novel hardware.

I balance that with hands-on systems coursework and projects that force me to think like a kernel developer. My Diary with AI Feedback side project couples FastAPI, custom vector search, and a Raspberry Pi deployment; aggressively measuring API latency and memory footprint taught me to wire observability into every layer and to write scripts that catch regressions before shipping.

Even when the work leans hardware, I keep software instincts at the center. On an FPGA polyphonic synthesizer I rewrote floating-point DSP code into fixed-point kernels on a Nios-V soft core, added interrupt-driven diagnostics, and built Python harnesses to sweep parameter spaces. Those experiences make me comfortable bridging RTL, firmware, and the higher-level frameworks your ML partners rely on.

I want to contribute to Tenstorrent by writing maintainable low-level code, instrumenting kernels, triaging perf counters, and collaborating with ML engineers to get real models running fast. I am excited to keep learning about your toolchains, ISA extensions, and profiling workflows while helping the team ship production-grade software.

Thank you for your consideration. I would welcome the chance to discuss how I can help drive Tenstorrent’s AI software stack forward.

\vspace{1em}
Sincerely,\\[1.2em]
Yongkang Cheng

\end{document}
